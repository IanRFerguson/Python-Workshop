{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Neuroimaging\n",
    "---------------\n",
    "Why stop at applying ML algorithms to behavioral data when we can apply them to functional neuroimaging! This particular set of methods has exploded in psychology in the last 5-10 years. Let's start by defining some key terms that we'll use in this walkthrough.\n",
    "\n",
    "### Glossary\n",
    "--------\n",
    "* **fMRI** - Functional magnetic resonance imaging. Used to measure changes in blood flow to neural regions during a functional task\n",
    "* **Voxel** - A three-dimensional spatial representation of a neural region\n",
    "* **Mask** - The subset of voxels that you want to analyze (helps to reduce noise). Think of it like a stencil\n",
    "* **NifTI** - File format created by the Neuroimaging Informatics Technology Initative, used to represent high-dimensional data obtained from fMRI scans\n",
    "* **Classification** - ML algorithm that predicts target's class/group membership\n",
    "\n",
    "For a good primer on fMRI, see [this article](https://blogs.scientificamerican.com/observations/whats-a-voxel-and-what-can-it-tell-us-a-primer-on-fmri/)\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "Consider **nilearn** an extension of SK-learn, which we just discussed. In fact, both libraries were developed by the same team! Nilearn is optimized for multi-dimensional data, which makes it an obvious choice for fMRI analysis. We won't go too under the hood with the *nilearn nitty gritty*, but let's take a look at some features that nilearn is especially adept at.\n",
    "<br> <br>\n",
    "The dataset I've chosen to work with ([Haxby et al., 2001](https://science.sciencemag.org/content/293/5539/2425)) is a block-design study on **face** vs. **object** representation in the ventral temporal cortex. It consists of 6 participants and 12 total runs across 9 conditions (e.g., bottle, chair, face, cat, etc.).\n",
    "<br> <br>\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "haxby_data = datasets.fetch_haxby()\n",
    "target = haxby_data.func[0]\n",
    "\n",
    "print(\"Functional images located at: {}\".format(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the local file path for the fMRI images from Haxby et al., 2001. The .nii.gz format indicates that this data is in NifTI format, and is compressed (similar to \"zipping\" or compressing a directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "plotting.view_img(mean_img(target), threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "mask = haxby_data.mask_vt[0]\n",
    "\n",
    "mask_function = input_data.NiftiMasker(mask_img=mask, standardize=True)\n",
    "fmri_masked = mask_function.fit_transform(target)\n",
    "\n",
    "print(fmri_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_masked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting this, we'll be working with **464 voxels of interest** in the ventral temporal cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(fmri_masked[:200, :3])\n",
    "plt.title('Voxel Time Series')\n",
    "plt.xlabel('Scan number')\n",
    "plt.ylabel('Normalized signal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "behave = pd.read_csv(haxby_data.session_target[0], delimiter=\" \")\n",
    "conditions = behave[\"labels\"]\n",
    "\n",
    "list(behave[\"labels\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to FACE vs. CAT discrimination\n",
    "condition_mask = conditions.isin(['face', 'cat'])\n",
    "\n",
    "fmri_masked = fmri_masked[condition_mask]\n",
    "conditions = conditions[condition_mask]\n",
    "\n",
    "fmri_masked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We'll keep the **464 voxels of interest** but only need to analyze 216 volumes (these are the runs with cat or face stimuli presented to participants)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding with SVM Classifier\n",
    "------------------\n",
    "To decode these fMRI runs, we'll use a **Support Vector Machine (SVM) Classifier** - an SVM algorithm attempts to maximally separate Group A from Group B. In this example, we're attempt to separate voxels active in \"face\" processing from voxels active in \"cat\" processing.\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)\n",
    "\n",
    "<br> <br>\n",
    "We're going to call two important functions from our SVC:\n",
    "* **Fit** - 'Learns' the parameters of the model from the data <br>\n",
    "* **Predict** - Estimates which category the target belongs to\n",
    "\n",
    "<br> <br>\n",
    "Notably, we *cannot* predict on the same data that we used to fit the SVC parameters. That would give us a great result in a vacuum, but said results would likely not translate to other data.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate + fit SVC with masked fMRI data\n",
    "svc = SVC(kernel=\"linear\")\n",
    "svc.fit(fmri_masked, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fitted SVC to predict category membership\n",
    "predictions = svc.predict(fmri_masked)\n",
    "print(predictions)\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But does it mean anything?\n",
    "<br> <br>\n",
    "*Not really*. To obtain more meaningful results, we need to find a way to split our data into training and testing components.\n",
    "\n",
    "## Cross-Validation\n",
    "--------------\n",
    "SK-Learn has a built in K-Fold cross-validation function. We'll split our masked data into five testing segments (i.e., K = 5) ... this will give us a more accurate estimate of the SVC's performance on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "m=0\n",
    "scores = []\n",
    "\n",
    "for train, test in cv.split(X= fmri_masked):\n",
    "    conditions_masked = conditions.values[train]\n",
    "    svc.fit(fmri_masked[train], conditions_masked)\n",
    "    prediction = svc.predict(fmri_masked[test])\n",
    "    \n",
    "    m += 1\n",
    "    \n",
    "    score = round((prediction==conditions.values[test]).sum() / float(len(conditions.values[test])), 5)\n",
    "    scores.append(score)\n",
    "    print(\"Fold #{}:\\t\\t{}\".format(str(m), str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients to NIFTI\n",
    "------------------\n",
    "We end up with one coefficient value per voxel. These are **discriminating Beta weights** - in other words, when *Beta* is positive for a voxel it suggests that activation of that voxel is highly correlated with group membership determination.\n",
    "<br> <br>\n",
    "Thanks to Stanford's very own Russell Poldrack for [this excellent article](https://watermark.silverchair.com/nsm006.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAApowggKWBgkqhkiG9w0BBwagggKHMIICgwIBADCCAnwGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMvqtdetEkPWvDMIeFAgEQgIICTZnhu1Ss-XAhVgWkphHfspOAkRqGvStuOvnqI7XxYg8IaHmSNNq8T0sR9g_Bi5c3qN4mlmBZYlbolL7MdqkHkdTdT-ol8w3dxqTbqM_zICtyvrfKsjOZ7irSF_gwf6eSR1tGuXTNeo3GOJr9dNQ-JYDZy98S6oP2kPLHrLnIs8pL0kiDC0xC4SmU6CSmASyK3P6gYzjah8z_t14UW2SOtFiUwqndZAVKdc__SalpC68leYisOURS3x5wOVlT0CJ9dDPuMW5MawIOjCjfiCkItvhsYL4fuJCgCmsqjOH3S8K7RxSUDekkaNxFb9SYzHbuXtwE8QlVW8e7QX0OafwKvkKBh4VRzcfQO3Hh4sOZW7YHNJ9RCxjABQBh1CUGWPxnm87LJVzfn152xl2qU1y3pFm5iYCnTPzp6bhImHU_IqJHq5K5ohriWgMC1Ip-tVt2OdjI0Zi1rg4SohRsGXy7oBCxbMgJY5XF9Kgn5NYJ9S6HwdCHiKf5buEF_m4sW2plWGTmbVY9l-a2mQ59EhOzFYIE2dXAA8-av8Pz8cE86YJ3M_jQLYTNT1Gam52xlqqDMZXMPXFrlQ-hMeFKhAOG7Qqg5txuJDDuJ5LmR2T4oq5NBYCCqmi_ICGmbsOdwJGjX4MSiSdN9-19QOL3RlkXzqCZV86d98B7NW7kGDZYHaO9AKqIPUAWevrwly9_-i3QAi8cmWQ-1ZqzD4CpLhjylyWc5vgPTxKR5syt3e1IXdovvEhXtAXu-9lM_UzUFT6p-wYzoNcga3P9Ij-9Trg) on Region of Interest analysis in fMRI! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ = svc.coef_\n",
    "\n",
    "coef_[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_image = mask_function.inverse_transform(coef_)\n",
    "\n",
    "from nilearn.plotting import plot_glass_brain, show\n",
    "\n",
    "# Plot coefficients from SVC\n",
    "plot_glass_brain(coef_image, colorbar=True, plot_abs=True)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "------------\n",
    "* [Sci-Kit Learn Documentation](https://scikit-learn.org/stable/)\n",
    "* [Nilearn Documentation](https://nilearn.github.io/user_guide.html)\n",
    "* [PyMVPA Documentation](http://www.pymvpa.org/docoverview.html)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Up Next**: [Additional Resources](http://localhost:8888/notebooks/Documents/ACADEMIA/04_Stanford/02_Projects/03_Professional-Dev/00_Python-in-Psych/00/Additional%20Resources.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
