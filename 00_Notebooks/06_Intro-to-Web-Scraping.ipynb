{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.python.org/static/community_logos/python-logo-master-v3-TM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will detail some basic methods for scraping data from the internet. \"Scraping\" essentially means isolating the data from its source and making it more interpretable - scraping a table from your favorite sports team's website and turning it into a Pandas DataFrame, for example.\n",
    "<br> <br>\n",
    "Actually, that's exactly where we'll start..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping with Pandas\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The webpage we want to scrape\n",
    "target = \"https://www.basketball-reference.com/teams/GSW/2020.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a built-in function for scraping HTML tables. It's not fool proof by a long stretch, and doesn't work for more densely-embedded tables (JSON, XML, etc.) but it's an excellent start! Since we've defined our target URL above, we can plug it right in to Pandas' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! If you visit the webpage (click [HERE](https://www.basketball-reference.com/teams/GSW/2020.html)) you'll see that Pandas read the first table on the page into our program.\n",
    "<br><br>\n",
    "\"This doesn't look especially interpretable to me\" <br><br>\n",
    "You're not wrong! My best practice here is to include an index after the method call to tell Python <i>exactly</i> what you want it to scrape - this has the added benefit of converting the table into a DataFrame, rather than a bunch of Series like we see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call with indexing\n",
    "pd.read_html(target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape second table from page\n",
    "pd.read_html(target)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are a ton of tables on this page and the Pandas HTML scraper is only nimble enough to find the first one. Luckily for us, there are much stronger scraping tools at our disposal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping with BeautifulSoup\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic NLP and Text Embedding\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
